# The **[R]{.sans-serif}** *Environment*

**[R]{.sans-serif}** has been described as "an environment for
statistical modeling and graphics.\" The word *environment* instead of
*package* is one of the main reasons **[R]{.sans-serif}** is distinct
from other statistical programs. A *package* gives a user a fixed set of
tools. An *environment*, in addition to providing a fixed set of tools,
allows users to customize those existing tools and to develop their own
tools to suit their unique needs.

## Why Are There So Many Use**[R]{.sans-serif}**s?

These are some of the likely reasons you are here today.

### Statistical Tools

The **[R]{.sans-serif}** environment contains many powerful tools for
statistical analysis including

-   Linear and Generalized Linear Models

-   Survival Analysis

-   Random and Mixed Effects Models

-   Classification and Clustering

-   Sample Size and Power Calculations

-   Multivariable analysis (FA, PCA, SEM, ...)

In this workshop will see and use sample code for many of these
analyses.

### Graphics

Many researchers use **[R]{.sans-serif}** specifically for its excellent
graphing capabilities. Graphics in **[R]{.sans-serif}** are easy to
implement and modify. Once you are comfortable with
**[R]{.sans-serif}**, you will have several powerful graphics packages
at your fingertips. "Base graphics" has been supplemented by "grid
graphics" and the "grammar of graphics."

### Extensibility

Despite the extensive built-in statistical techniques, the most powerful
feature of **[R]{.sans-serif}** is the ability for users to extend
**[R]{.sans-serif}**'s base capabilities. **[R]{.sans-serif}** is a
full-fledged programming language that allows users to write their own
functions. Users can contribute their own "packages" that build on
**[R]{.sans-serif}**'s base capabilities. Users have contributed over
13,700 packages to CRAN (Comprehensive **[R]{.sans-serif}** Archive
Network) as of March 2019.

### Cost (\$0)

**[R]{.sans-serif}** is open source: the source code behind the software
is free for all to examine and extend. **[R]{.sans-serif}** grows by
leaps and bounds as people from all fields develop new functions for use
within **[R]{.sans-serif}**'s computing environment. This is part of
what makes **[R]{.sans-serif}** so useful. Many complex statistical
routines that not yet available in other statistical software systems
have been programmed in **[R]{.sans-serif}**, and these routines are
freely available for use by anyone.

### Operating Systems and GUIs

**[R]{.sans-serif}** runs on Windows, MacOS, and a variety of Unix
platforms. In Windows, there are at least four GUIs: the standard
**[R]{.sans-serif}** GUI, **[R]{.sans-serif}**Studio,
Tinn-**[R]{.sans-serif}**, and **[R]{.sans-serif}** Commander. We will
be using the standard **[R]{.sans-serif}** GUI some and
**[R]{.sans-serif}**Studio (`www.rstudio.com`) more. It organizes the
user's screen into panes that display programs/scripts, objects,
graphics, and the **[R]{.sans-serif}** console. **[R]{.sans-serif}**
Commander (`www.rcommander.com`), developed by John Fox at McMaster
University, is a front-end for interacting with **[R]{.sans-serif}**
through menus. This package can be useful to **[R]{.sans-serif}**
beginners. It provides helpful tools for getting started and then
displays the underlying **[R]{.sans-serif}** code for each analysis to
help the user learn the programming language. Tinn-**[R]{.sans-serif}**
(`sourceforge.net/projects/tinn-r/`) is another enhanced editor from
Jose Claudio Faria.

### Reproducible Research

**[R]{.sans-serif}** has several methods for integrating code, output,
and interpretation into a single document. This allows consumers to
confirm the original analysis and to investigate other approaches.

## Why Isn't Everyone a Use**[R]{.sans-serif}**?

### One and Only

Many users of statistics learn only one package: the one taught in their
first introductory statistics course. Historically this has rarely been
**[R]{.sans-serif}**, but there are signs this is changing.

### Steep Learning Curve

It can take time to get comfortable and productive with
**[R]{.sans-serif}**. A user often interacts with **[R]{.sans-serif}**
through typed commands, rather than via a point-and-click menu system.
For users with minimal background writing code, it can take some time to
get the hang of using **[R]{.sans-serif}**. Furthermore, while the help
system is comprehensive for the base packages, it's quality ranges for
community-written packages. Don't get frustrated! You don't have to be
an expert programmer to learn **[R]{.sans-serif}**. The benefits
(flexibility, extensibility, speed) are worth spending some time up
front.

## Suggestions for Learning **[R]{.sans-serif}**

-   Learn interactively! Reading can help only so much. Most people
    learn **[R]{.sans-serif}** best by typing commands themselves.

-   Ask questions of current **[R]{.sans-serif}** users, e.g., your
    instructor.

-   Look at (and retype) lots of sample code. Experiment with
    modifications of the code. You won't break **[R]{.sans-serif}**.
    You'll see many examples in this workshop but there is much more
    online.

-   Don't worry about getting errors. Experienced **[R]{.sans-serif}**
    users make errors all the time. Base **[R]{.sans-serif}** has
    excellent error messages that are good learning opportunities
    themselves.

    -   `www.r-project.org`: The **[R]{.sans-serif}** Home page, the
        central webpage for the **[R]{.sans-serif}** project. Here you
        will find links for downloading **[R]{.sans-serif}**,
        downloading additional packages for **[R]{.sans-serif}**, and
        almost everything else that you would like to know about the
        software or the people behind it.

    -   `cran.r-project.org/web/views/`: Task views summarize the most
        important packages involved in a subject field or analysis type.

    -   `journal.r-project.org`: The **[R]{.sans-serif}** Journal

    -   `stats.stackexchange.com`: Cross-Validated

    -   `www.r-bloggers.com`

    -   `stats.idre.ucla.edu/r/`: Institute for Digital Research and
        Education at UCLA

    -   `socialsciences.mcmaster.ca/jfox/`: John Fox's home page

    -   `sas-and-r.blogspot.com/`: Examples of code to perform same task
        in each language

## How To Obtain **[R]{.sans-serif}**

**[R]{.sans-serif}** is already installed on the lab workstations. The
following information is useful if you need to install
**[R]{.sans-serif}** on another machine.

At the **[R]{.sans-serif}** Project Web Page (`www.r-project.org`) the
most important link is at the left hand side of the screen, under the
"Download" heading. Click on the CRAN link (Comprehensive
**[R]{.sans-serif}** Archive Network), and, after you choose one of the
U.S. mirrors, you will be taken to the page that you will use to
download everything **[R]{.sans-serif}**-related.

Once you find the CRAN web page, take the following steps to obtain
**[R]{.sans-serif}**:

1.  Click on "Download **[R]{.sans-serif}** for XXX" that best describes
    your operating system (Linux, OS X, Windows).

2.  When using Windows, click on the "base" subdirectory. This will
    allow you to download the base **[R]{.sans-serif}** packages.

3.  Click the "Download **[R]{.sans-serif}** 3.X.X for Windows" link.
    **[R]{.sans-serif}** is updated quite frequently. At the time of
    this printing, version 3.5.2 is available. Save the .exe file
    somewhere on your computer.

4.  Double-click on the .exe file once it has been downloaded. A wizard
    will appear that will guide you through the setup of the
    **[R]{.sans-serif}** software on your machine.

5.  Once you are finished, you should have an **[R]{.sans-serif}** icon
    on your desktop that gives you a shortcut to the
    **[R]{.sans-serif}** system. Double-click on this icon, and you are
    ready to go!

### How to Obtain RStudio

**[R]{.sans-serif}**Studio is already installed on the lab workstations.
The following information is useful if you need to install
**[R]{.sans-serif}**Studio on another machine.

Visit (`www.rstudio.com`) and download the free desktop version of
**[R]{.sans-serif}**Studio.

### Contributed Packages

What exactly are "additional contributed packages"? **[R]{.sans-serif}**
is an open source software environment, so users are free to explore the
code behind the software and to write their own new code. Statisticians,
researchers, and other users have written additional packages for
**[R]{.sans-serif}** that perform complex analyses (and simple ones!).
In order to use these packages and the functions within them, you first
need to download them. Base **[R]{.sans-serif}** comprises many
packages, but odds are that you will discover an uncommon analysis
technique in your research that requires you to install an additional
package that is not included by default.

These additional packages are usually found CRAN. However, there are
other repositories as well (e.g., bioconductor, github).

# Getting Started with **[R]{.sans-serif}**

Launch **[R]{.sans-serif}** from the Start Menu or the desktop icon.
(We'll shift to **[R]{.sans-serif}**Studio after we have some
familiarity with using **[R]{.sans-serif}** interactively.)

## Using **[R]{.sans-serif}** as a Calculator

**[R]{.sans-serif}** can perform basic arithmetic operations. Type the
following expressions at the command prompt in the **[R]{.sans-serif}**
console window.

`> 5+3`

`> 5-3`

`> 5/3`

`> 5*3`

`> 5^3`

`> 4 + 2 * 3`

`> (4 + 2) * 3`

If you have missing input (represented in **[R]{.sans-serif}** by NA),
the output will likely be missing:

`> (4 + NA) * 3`

If you try something mathematically shoddy, you will likely be told:

`> 0 / 0`

`> 1 / 0`

`> -1 / 0`

**[R]{.sans-serif}** has many built-in mathematical functions.

`> log(100)`

`> sqrt(9)`

`> sqrt(-9)`

`> sqrt(-9 + 0i)`

This is your first indication that an **[R]{.sans-serif}** function may
behave differently depending on the *type* of input.

`> sqrt(NA)`

`> exp(1)`

An *argument* is a parameter that is passed to a function. The `sqrt`
and `exp` functions only take a single argument. Many functions,
including `log`, take more than one argument. Arguments are separated by
commas.

`> round(5.123, 2)`

If not all arguments are provided, **[R]{.sans-serif}** may use a
default value.

`> round(5.123)`

Some other basic functions:

`> ceiling(5.123)`

`> floor(5.123)`

The "Remainder" and Integer Division operations:

`> 17 %% 5`

`> 17 %/% 5`

**Review of logarithms** If $a^y = x$, then $\log_a(x) = y$. For
example, $10^2 = 100$ and $\log_{10}(100) = 2$. Three common choices of
the base are $10$, $2$, and $e$. What is the default choice in
**[R]{.sans-serif}**?

`> log(10)`

`> log(2)`

`> log(exp(1))`

Suppose you are working with a dataset and you wish to apply the
$\log_{10}$ transformation. How can we instruct **[R]{.sans-serif}** to
take logarithms base 10? **[R]{.sans-serif}**'s help pages are good
sources of information for questions such as these. Two ways to view a
function's help page are '?' and 'help'. A more generic approach might
be searching "take log in r" with your favorite search engine.

`> ?log`

`> help(log)`

The `log` function can take two arguments including the *base* argument.
Arguments can be specified in several ways.

The argument name can be stated explicitly:

`> log(x=25, base=5)`

The argument name can be abbreviated as long as the abbreviation is
unique:

`> log(x=25, b=5)`

Not all arguments need to be named:

`> log(25, b=5)`

`> log(b=5, 25)`

We don't have to use the argument names at all, in which case the
arguments are matched by the order listed. Compare

`> log(25, 5)`

`> log(5, 25)`

**[R]{.sans-serif}** may return an error if you incorrectly name a
function argument.

`> log(25, be=5)`

## Making Comparisons: Logical Operators

**[R]{.sans-serif}** has logical operators that will return "TRUE" or
"FALSE" (or possibly "NA" if you have missing values).

`> 5 == 6`

`> 5 != 6`

`> 5 < 6`

`> 5 > 6`

`> 5 <= 6`

`> 5 <= NA`

`> 5 <= Inf`

`> !TRUE`

`> (1 + 2) == 3`

**[R]{.sans-serif}** has "and" and "or" operators (there are others):

`> (5 < 6) & (7 == 8)`

`> (5 < 6) | (7 == 8)`

`> (5 < 6) | NA`

**Be careful of comparisons and floating point arithmetic**:

`> (.1 + .2) == .3`

`> 5 == sqrt(5)^2`

`> 5 - sqrt(5)^2`

The `all.equal` function will test if two values are "close enough":

`> all.equal(5, sqrt(5)^2)`

`> ?all.equal`

This is not bug of **[R]{.sans-serif}**. It is a feature of computers
using binary representation of floating point numbers and storing them
with finite precision. This is common enough to make the
**[R]{.sans-serif}** FAQ (7.31):
`https://cran.r-project.org/doc/FAQ/R-FAQ.html`. To quote from "The
Elements of Programming Style" by Kernighan and Plauger: "10.0 times 0.1
is hardly ever 1.0."

## Vectors and Sequences

**[R]{.sans-serif}** is a 'vectorized' language. Many functions operate
on an entire vector of numbers as easily as on a single number. This
feature allows the user to think in terms of manipulating entire data
variables rather than one data element at a time. For example (once we
have learned about storing objects), we can write `mean(Height)` or
`hist(Height)` to analyze a variable, rather than working with the
individual data values.

Thus it is important to be able to create and manipulate vectors.
Numbers can be combined into a vector with the function 'c', which
stands for *combine*.

`> c(3, 9, 2)`

The following commands produce exactly the same output, namely a vector
with the integers 1 to 10. In **[R]{.sans-serif}**, there are often many
ways of doing the same thing.

`> c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)`

`> 1:10`

`> seq(1, 10, 1)`

`> seq_len(10)`

`> ?seq`

You can specify a sequence's increment or length using the *by* and
*length* arguments.

`> seq(0, 200, by=4)`

`> seq(0, 200, length=13)`

`> rep(3, 12)`

In **[R]{.sans-serif}**, functions can be nested. In the following
examples, the inner function, `c`, is used to create a vector and the
outer function uses that vector as an argument.

`> rep(c(3,9,2), times=4)`

`> rep(c(3,9,2), each=4)`

`> rep(c(3,9,2), length=12)`

`> rep(c(3,9,2), times=c(2,9,1))`

## Matrices and Arrays

In **[R]{.sans-serif}**, a matrix or an array is just a vector with a
dimension *attribute*. The `matrix` command can rearrange a vector into
a matrix.

`> matrix(1:12, nrow=3)`

What happens if we don't specify the number of rows using the argument
`nrow`?

`> matrix(1:12)`

The result is still a matrix, but the default is to put each element in
a separate row. What happens if we specify an inappropriate number of
rows?

`> matrix(1:12, nrow=5)`

When the number of rows and the number of elements are not coherent,
**[R]{.sans-serif}** issues a warning.

A vector has 1 dimension; a matrix has 2 dimensions; an array can have
any number of dimensions. These have 3 dimensions:

`> array(1:12, dim=c(2,2,3))`

`> array(1:12, dim=c(2,3,2))`

# Using Scripts

Until now, we have submitted each command to **[R]{.sans-serif}** by
typing directly at the command prompt. In almost all situations, it is
**much** better to type code in a separate file called a script file.
There are many advantages of using script files.

-   Repeatability

-   Editing

-   Submitting many commands at once

## Scripts in **[R]{.sans-serif}** GUI

To open an **[R]{.sans-serif}** script, go to File `->` New Script. You
can type your commands in the resulting windows. It is useful to save
your script files with a .R extension. Then the operating system
recognizes this as an **[R]{.sans-serif}** file.

After opening a new script, type

`> history()`

A new window will open with the last 25 commands you have used. You can
get a longer history with, say,

`> history(100)`

Select all your commands and copy-paste them to the new script. Save the
file with a .R extension.

There are several ways of submitting commands from the
**[R]{.sans-serif}** script window.

-   Copy and Paste from the script window to the interpreter window

-   Control-r

-   The `source` command. If your file is saved as *myfile.R*, you can
    run all the commands in the file by typing the following line at the
    command prompt.

    `> source("myfile.R")`

    In order for **[R]{.sans-serif}** to read your script, you must use
    the full path or be in the correct working directory. To change the
    current working directory, go to File `->` Change Dir, then browse
    to the appropriate folder.

    To see the files in the current working directory, type:

    `> dir()`

    Another possibility is to find the file using

    `> source(file.choose())`

    but this does not change the working directory.

## Comments

Documentation and formatting are essential to writing effective
**[R]{.sans-serif}** code. If you come back to a project after a few
months (days? hours?), you want to know what the code is doing without
retracing every single step. Comments in **[R]{.sans-serif}** can be
inserted with the `#` symbol. **[R]{.sans-serif}** will not process the
rest of the line after the `#`.

`> 5 < 6`

`> 5 # < 6`

The following is an example of a commented **[R]{.sans-serif}** script.
Some of the functions we have used before; others will be explained
later. Let's open it in **[R]{.sans-serif}**Studio and see what it does.

## **[R]{.sans-serif}**Studio

**[R]{.sans-serif}**Studio is an interface to **[R]{.sans-serif}**. It
organizes the user's screen into windows that display programs
(scripts), objects, graphics, and the **[R]{.sans-serif}** interpreter.
Launch **[R]{.sans-serif}**Studio from the start menu. Click on the
folder in the upper left corner and browse to the folder containing the
script "sample script.R". The following should open in the upper left
window.

## Sample Script

\# sample script.R

\# Chris Andrews

\# Created 2015 04 01

\# Last Modified 2019 02 03

\# This script analyzes the Life Cycle Savings data.

\# See help(LifeCycleSavings) for more details.

\#

\# Shorten the name and make local copy

Life = LifeCycleSavings

\# Examine Structure

head(Life)

dim(Life)

str(Life)

\# Descriptives

summary(Life)

\# Pairwise associations

cor(Life)

pairs(Life)

\# Fit a multiple regression model

mr.mod = lm(sr   pop15 + pop75 + dpi + ddpi, data=Life)

summary(mr.mod)

anova(mr.mod)

\# Plot the fit

par(mfrow=c(2,2), las=1, mar=c(4.5,4.5,2,1))

plot(mr.mod)

Use "Ctrl-Enter" to submit each line of the script. Take note of what
happens as each line is submitted to the interpreter.

# Objects

## Assignment

An *object* is an entity that contains information and can be
manipulated by commands. **[R]{.sans-serif}** has two main commands for
assigning an object: '$<$- ' and '='.

`> x <- 5`

`> x = 5`

We will use '=' throughout this document. However, many
**[R]{.sans-serif}** users prefer '`<-`', because '=' is used for other
things, too. A third method is very rarely used:

`> 5 -> x`

Each of the previous commands assigns the number `5` to the object `x`.
Notice that **[R]{.sans-serif}** produces no output when the above
commands are run. In order to see what **[R]{.sans-serif}** has done,
type:

`> ls()`

and/or look at the environment window in the upper right corner. Now
type

`> x`

When you submit a command to **[R]{.sans-serif}**, one of three things
can happen.

1.  You see a result: e.g.,

    `> x`

    **[R]{.sans-serif}** prints the value of the expression.

2.  You see nothing except another command prompt: e.g.,

    `> y = log(x)`

    For an assignment, **[R]{.sans-serif}** stores the value of `log(x)`
    in the object `y`, but produces no output.

3.  You see an error message: e.g.,

    `> y = lg(x)`

    Look at error messages -- they can be informative!

## Manipulating Objects

We can perform mathematical operations on objects such as `x`.

`> x + 2`

Notice that x has not changed:

`> x`

We can change the value of x:

`> x = x + 2`

`> x`

*Cautionary Tip*: It is very important to use caution when writing over
a variable as above. If you need to use `x` later on, be sure you are
using the correct value!

Start from scratch and perform operations on two objects.

`> x = 5`

`> y = 2`

`> x - y`

If two objects are assigned to have the same value, they can be changed
to differ. (Assigned by value not by assigned by reference, for those of
you who know what that means.)

`> a = 3`

`> b = a  # Note: Assignment`

`> b == a # Note: Test of Equality`

`> a = a + 1`

`> a`

The value of `b` didn't change.

`> b`

Assign a vector of numbers to the object `x`

`> x = c(3, 5, 9, 10)`

`> x`

Get a list of the objects in the workspace.

`> ls()`

Remove an object.

`> rm(x)`

## Indexing Objects

Situations frequently arise when you want to access select portions of a
database. In this section, we discuss how to extract elements of vectors
and matrices.

### Indexing Vectors

`> x = c(13,21,99,10,0,-6)`

Suppose that we only need the first element of the vector `x`. To
extract the first element, we type the name of the entire vector,
followed by the index we want to extract enclosed in brackets.

`> x[1]`

We can save the extracted part to a new object

`> z = x[1]`

`> z`

We often will want to extract more than one element of a vector. Each of
the following two lines of code extracts the first three elements of the
vector `x`.

`> x[c(1,2,3)]`

`> x[1:3]`

What happens if we try to extract the first three elements in the
following way?

`> x[1,2,3]`

Elements can be extracted in any order and elements can be extracted any
number of times. All of the following are legitimate methods of
extracting multiple elements from a vector.

`> x[c(2,4,5)]`

`> x[c(4,5,1)]`

`> x[c(5,1,5,2,1,1,1,5)]`

The following code extracts all elements of x *except* the second.

`> x[-2]`

What will this do?

`> x[-c(2,4)]`

### Indexing Matrices

To extract an element from a matrix, you may specify two values: the row
value and the column value. The row and column are separated by a
column.

`> M1 = matrix(1:12, nrow=3, byrow=TRUE)` \# (this is obj5 from before,
so M1 = obj5 works too)

`> M1`

Pick out the number from the second row and third column.

`> M1[2,3]`

You can simultaneously select multiple rows and multiple columns.

`> M1[2,c(1,3)]`

`> M1[c(2,3),c(1,2)]`

If nothing is specified in the row position (before the comma), then
every row is kept. Similarly, every column is kept if nothing is
specified in the column position.

`> M1[,c(2,3)]`

`> M1[c(1,2),]`

If nothing is specified in either position, the entire matrix is
returned.

## Index Assignment

In addition to extracting certain indices, it is also possible to
*assign* new values to certain elements of a vector or matrix.

The following two lines of code change an element of the vector `x` and
the matrix `M1`.

`> x[3] = 5`

`> M1[2,3] = 6`

## Aside: Missing Index?

If an index is missing, it might be any index. This is rarely what you
want: Avoid missing values in your index.

`> x[NA]`

## Object Classes

So far we seem to have been working exclusively with numeric objects.
**[R]{.sans-serif}** can store objects of many different types. Suppose
you are working with a data set that includes both quantitative and
categorical variables. **[R]{.sans-serif}** can store these as different
classes. Let's begin by looking at two basic classes, `numeric` and
`character`.

`> x = 12`

`> class(x)`

`> y = c(3,5,2)`

`> class(y)`

**[R]{.sans-serif}** stores both the number `12` and the vector
`c(3,5,2)` as an object of the class *numeric*. Strings are stored as
*characters*.

`> x = "Hi"`

`> class(x)`

`> y = c("sample", "string")`

`> class(y)`

Elements of vectors and matrices must be of the same class.

`> mix = c("aa", -2)`

`> mix`

`> class(mix)`

`> mix[2]`

`> class(mix[2])`

When working with data, this will create problems if a column
representing a quantitative variable contains character text. The
numeric is *promoted* to character.

## How to Mix Variables of Different Classes

Matrices are not well-suited for storing data sets. Data sets frequently
contain different types of variables (quantitative, qualitative).
Matrices force all elements to be of the same class. A `data.frame` is
particularly adept at handling data of different classes.

`> num = c(2,9,6,5)`

`> char = LETTERS[c(24,24:26)]`

`> dat = data.frame(num, char, stringsAsFactors=FALSE)`

`> dat`

`> class(dat)`

Though data analysts will rarely spend their time investigating a data
set as small this one, exploring data sets such as these can be helpful
in learning **[R]{.sans-serif}**'s capabilities. In the following code,
we investigate the names and dimensions of the data set `dat`; we also
investigate the properties of the columns of `dat`.

`> names(dat)`

`> dim(dat)`

`> nrow(dat)`

`> ncol(dat)`

`> class(dat[,1])`

`> class(dat[,2])`

**[R]{.sans-serif}** stores the first column as *numeric* and the second
column as a *character*. `summary` gives a numerical summary of numeric
variables and little useful information for character variables.

`> summary(dat)`

It is likely that you want to store a categorical variable as a *factor*
rather than a character vector. The default behavior of data.frame to do
the conversion.

`> dat = data.frame(num, fac=char)`

Now **[R]{.sans-serif}** stores the first column as *numeric* and the
second column as a *factor*. `summary` gives a numerical summary of
numeric variables and a table for categorical variables.

`> class(dat[,2])`

`> summary(dat)`

Keeping track of column numbers can be tedious. It is often more
convenient and cleaner to index by the column name. Name indexing uses
the dollar sign (`$`) or double square braces (`[[]]`).

`> dat$num # Or dat[["num"]]`

`> dat$fac # Or dat[["fac"]]`

Factors can be created explicitly (not just as a side effect of the
`data.frame` function)

`> fac = factor(char)`

The `levels` function returns the levels of a factor.

`> levels(fac)`

# Data for Analysis

## Creating Data: Random numbers

**[R]{.sans-serif}** has excellent number generating capabilities. This
makes **[R]{.sans-serif}** a good programming environment for simulation
studies. The `rnorm` function randomly draws from a univariate normal
distribution. (The 'r' stands for random.)

`> rnorm(3)`

`> rnorm(3, mean=10, sd=0.5)`

`> x = rnorm(100, mean=10, sd=2)`

`> hist(x, col="blue", main="100 Random Numbers from a Normal Distribution")`

See `help(rnorm)` for more details. You can generate from many
distributions using functions such as `rnorm`, `rt`, `rf`, `rbinom`,
`runif`, `rexp`, and `rgamma`.

### Functions about Probability Distributions

**[R]{.sans-serif}** is also a source of exact probability tables and
therefore eliminates the need to flip to the back of a statistics
textbook to calculate probabilities under curves or critical values. For
example, you can calculate the 95% critical value of a t distribution
with 34 degrees of freedom with the following command:

`> qt(0.975, df=34)`

We can find the critical value of a standard normal distribution using
`qnorm`. (The 'q' stands for quantile function.)

`> qnorm(0.975)`

We can also find cumulative probabilities needed for p-values. (The 'p'
stands for probability function.)

`> pnorm(-1.96)`

## Reading data from files

Researchers often analyze data that are stored in spread-sheet or text
formats. The most common function to import data is `read.table`. Before
looking at an example of how `read.table` is used, let's consider common
issues that arise when reading data into any program.

-   What is the file name?

-   What is the file type?

-   Where is the file located?

-   Does the file include variable names?

-   How are fields separated (e.g., tab, comma, white-space)?

-   How are missing values stored?

The `read.table` function is used in **[R]{.sans-serif}** for importing
text data into data set objects. This function requires that you have a
valid data table in a text format (where rows are observations, and
columns are variables) with every cell containing a data point. If there
are any blanks, the function may not work properly. Missing values by
default should be coded as NA before attempting to import text data.
Columns should be separated by white space.

The `read.table` function has arguments that allow the user to control
data importation features.

`> help(read.table)`

The four most important arguments to the `read.table` function are
*file*, *header*, *sep*, and *na.strings*. Let's practice by importing
the *samp2.dat* text file. Be sure to first change the working directory
to the folder that contains *samp2.dat*. In **[R]{.sans-serif}**Studio
you can either use the Session \> Set Working Directory menu option or
use the `setwd()` function.

`> gro = read.table("groceries.txt")`

`> head(gro)`

`> str(gro)`

By passing only the *file* argument to `read.table`, we have left all
other arguments at their default values. Notice that
**[R]{.sans-serif}** reads the variable names to be the first row of
data rather than the column names. **[R]{.sans-serif}** has stored the
columns of *gro* as a factor.

`> gro = read.table("groceries.txt", header=TRUE)`

`> head(gro)`

`> str(gro)`

`> tail(gro)`

`> summary(gro)`

`> dim(gro)`

## Importing from Excel

"How do I import my data into **[R]{.sans-serif}** from Excel?" is a
common question.

My answer is often: "Don't!"

Excel spreadsheets contain attributes and formatting that often cause
difficulty when transferring files between applications. In particular,
dates, or text that looks like dates, are troublesome. Zip codes and
MRNs lose their leading zeros. The easiest thing to do is to first
export the data into either a tab-delimited (.dat, .tsv) or comma
separated values (.csv) file. After the file is in a more portable
format, then use `read.table` or `read.csv` into **[R]{.sans-serif}**.

We use the *samp2.csv* file for practice.

`> dat2 = read.csv("samp2.csv", na.strings=c(NA, 88, 999))`

`> dat2`

`read.csv` simply invokes `read.table` with a different set of default
arguments. Notice that the default for `read.csv` is to include a
header.

`> help(read.csv)`

### Straight from Excel

However it is possible to skip the .csv step using one of several
**[R]{.sans-serif}** packages. Option 1: Use the Import Dataset button
above the environment window in **[R]{.sans-serif}**Studio (obviously
this only applies if using **[R]{.sans-serif}**Studio). Option 2: Use
the `read_excel` function in the `readxl` package (actually, Option 1
uses Option 2). Option 3: use package `xlsx`. Option 4: \...

These approaches may result in slightly different data formats. This is
not a problem, just be certain to investigate your data after loading.

## Data from other Formats

**[R]{.sans-serif}** can read directly from other formats with varying
levels of success. Functions exist for fixed width formats, .sas7bdat,
SAS xport, SPSS, Stata, DBF, \...

## Exporting Data

**[R]{.sans-serif}** has facilities for exporting data. Suppose you make
changes to a data set within **[R]{.sans-serif}** and you want to save
those changes permanently in a .csv or .xls file. The `write.csv`
command exports an **[R]{.sans-serif}** object to a text file. All you
have to do is give `write.csv` two arguments: 1) the
**[R]{.sans-serif}** object to be exported, and 2) the name of the file.

For example, `write.csv(M, "newfile.csv")` will export the
**[R]{.sans-serif}** object `M` to a newly created file `newfile.csv`.
We will modify `dat2` to include an `id` variable, and we write the
updated data object to a csv file.

`> dat2$id = 1:nrow(dat2)`

`> dat2`

`> write.csv(dat2, "newfile.csv")`

**[R]{.sans-serif}** can also write to text files using `write.table`.

## Missing Values in Data files

Data files can represent missing data in many ways. Often Excel files
have blank cells. Text files may use a special value such as 999 to
represent missingness. SAS uses a period. Different codes may specify
different reasons for the missingness such as non-response or an
unreasonable value.

There are several ways to convert these conventions to NA in
**[R]{.sans-serif}** so they will (more likely) be treated properly in
analyses. (There are entire statistics courses on "properly" dealing
with missing data.)

Suppose that the $88$ and $999$ are codes indicating missing values. We
want **[R]{.sans-serif}** to interpret these values as missing rather
than numeric. We can change these values to NA after reading in the
data. First we identify them and then replace them by NA.

`> dat = read.csv("samp2.csv")`

`> dat`

`> dat$z == 88 | dat$z == 999`

`> dat$z[dat$z == 88 | dat$z == 999]`

`> dat$z[dat$z == 88 | dat$z == 999] = NA`

`> dat`

### The `which` function

While we are on the subject of missing data (NA) and logical values
(TRUE, FALSE), I want to mention the `which` function. It statement
takes a logical statement (or a series of logical statements, some which
may be missing) as an argument. It returns the indices for which the
logical statement is TRUE.

`> a = c(6, 9, 10, 2, 999, NA)`

`> is.na(a)`

`> which(is.na(a))`

`> which(!is.na(a))`

`> a == 999`

`> a[a == 999]`

`> which(a == 999)`

`> a[which(a == 999)]`

`> a[which(a == 999)] = NA`

`> a`

`> is.na(a)`

The `which` command is a very powerful tool for data management.
Consider the following three scenarios:

-   You have a data set and wish to perform an analysis on only males.

-   All missing values have been coded as 99, 888, or 999.

-   A scatterplot reveals several outliers, and you need to identify the
    cases corresponding to the outliers.

In each scenario, `which` can be used to select the appropriate subset
of the data.

# Student t-tests

A t-test is a statistical hypothesis test in which the test statistic
follows a t-distribution. Three common applications of the t-test are:

-   A one-sample t-test of whether the mean of a normally distributed
    population is a particular value ($H_0: \mu = 70$)

-   An independent samples t-test to determine whether the means of two
    normally distributed populations are equal ($H_0: \mu_1 = \mu_2$)

-   A paired samples t-test to determine whether the means of two
    normally distributed populations are equal ($H_0: \mu_1 = \mu_2$)

Another t-test arises when testing whether a regression parameter equals
0 ($H_0: \beta_1 = 0$).

## One-sample t-test

Clean up the workspace and import `height.csv` into
**[R]{.sans-serif}**.

`> rm(list=ls()) # removes all objects`

`> dat = read.csv("height.csv", header=TRUE)`

`> head(dat)`

Let's start with a one-sample t-test. Test the hypothesis that the
population mean height for men is 70 inches ($H_0:\mu_{men} = 70$)

First we need to get the subset where gender $==$ male.

`> dat$gender == "male"`

`> men.ht = dat$height[dat$gender == "male"]`

Before doing any formal analyses, it is always a good idea to summarize
the data both numerically and visually.

`> summary(men.ht)`

`> boxplot(men.ht)`

`> hist(men.ht, main="My First Histogram in R!")`

The `t.test` function will perform a one sample t-test for the height of
men. Suppose we wish to test the hypothesis $H_0: \mu_{men} = 70$ versus
the alternative $H_a: \mu_{men} \neq 70$. We must give the `t.test`
function 1) the vector of male height values, and 2) the value of the
mean under the null hypothesis. The default alternative is two-sided.

`> t.test(men.ht, mu=70)`

What if you want to calculate a 90% confidence interval?

`> help(t.test)`

The *conf.level* argument will be used to change the confidence level.

`> t.test(men.ht, mu=70, conf.level= 0.90)`

`> t.out = t.test(men.ht, mu=70, conf.level= 0.90)`

`> names(t.out)`

`> t.out$conf.int`

## Independent Samples t-tests

Now suppose we wish to test whether there is a difference between the
population mean heights for men and women ($H_0: \mu_m = \mu_w$). Before
running the t-test, let's make side-by-side boxplots to visually compare
the heights of men and women.

`> boxplot(men.ht, women.ht)`

### The formula operator ($\sim$)

It is possible to avoid creating separate vectors for two groups that
you would like to compare. This is done with the formula operator and
many R functions can accept a formula as the first argument. The second
argument must then nearly always be the data.frame where the formula
should be evaluated.

`> boxplot(height `$\sim$` gender, data=dat)`

If you don't include the data argument, you'll likely get an error
message:

`> boxplot(height `$\sim$` gender)` \# error: data not found?

The variables in the `dat` data.frame can be made available temporarily
by wrapping the command inside a call to `with`:

`> with(dat, boxplot(height `$\sim$` gender))`

If you need access to the variables in a data.frame for an extended
session and you aren't going to change the variables in the data.frame,
you can use the `attach(dat)` function to access height and gender
directly. However, using `attach` is discouraged by some analysts. It
puts a second copy of the data.frame on the "search path" and can make
updating your data tricky. **Remember to `detach` when you are done.**

`> height`

`> attach(dat)`

`> height`

`> detach(dat)`

`> height`

Now perform the independent samples t-test.

`> t.test(height `$\sim$` gender, data=dat)`

# Chi-Square tests

Pearson's chi-square test is used to make two types of comparisons for
categorical variables. A *goodness of fit test* determines whether a
particular hypothesized distribution is reasonable for a categorical
variable. A *test of independence* assesses whether two categorical
variables are independent of each other.

## Goodness of Fit

Suppose a company wants to determine if employees are equally likely to
call in sick on any day of the week. That is, test the hypothesis
$$H_0: p_1 = p_2 = p_3 = p_4 = p_5$$ where $p_1$ represents the
probability that a random call-in sick occurs on Monday, etc. The
employer collects data and obtains the following table

::: center
  ----- ----- ----- ----- -----
    Mon   Tue   Wed   Thu   Fri
     34    18    19    12    26
  ----- ----- ----- ----- -----
:::

If $H_0$ is true, the expected value in cell $i$ is $E_i = np_i$, where
$n = 34 + 18 + 19 + 12 + 26 = 109$ and $p_i = 0.2$. The differences
between the observed and expected values are combined into the $\chi^2$
statistic. $$\chi^2 = \sum_i\frac{(O_i - E_i)^2}{E_i}$$ If the null
hypothesis is true, the $\chi^2$ statistic approximately follows a
$\chi^2(k-1)$ distribution, where $k$ is the number of groups (5). This
approximation is poor if the expected value in any cell is small.

We first need to get the data into **[R]{.sans-serif}**.

`> days = c(34, 18, 19, 12, 26)`

`> names(days) = c("Mon", "Tue", "Wed", "Thu", "Fri")`

`> days`

Many chi-square tests are performed using the `chisq.test` function.

`> chisq.test(days)`

**[R]{.sans-serif}** returns the $\chi^2$ test statistic, the degrees of
freedom, and the p-value. Notice that we didn't specify that we were
testing the hypothesis that were testing the hypothesis of *equal*
probabilities. By default, `chisq.test` assumes a test of equal
probabilities unless the user specifies otherwise. If, for some reason,
we wanted to test the hypothesis that $p_1 = 0.35$, $p_2 = 0.1$,
$p_3 = 0.1$, $p_4 = 0.1$, $p_5 = 0.35$, we can do so by passing the
probabilities to `chisq.test` in this way.

`> chisq.test(days, p=c(0.35, 0.1, 0.1, 0.1, 0.35))`

So far, the output for the chi-square tests have been limited. What if
we wanted to obtain expected values or cell residuals? We unleash more
of **[R]{.sans-serif}**'s capabilities by storing the value of the test
as an object.

`> cs.test = chisq.test(days)`

`> names(cs.test)`

`> cs.test$expected`

`> cs.test$statistic`

`> cs.test$residuals`

## Chi-Square Test of Independence

A Chi-Square Test of Independence tests for a relationship between two
categorical variables. We will use the "UCBAdmissions data set" to
illustrate.

`> data()`

`> UCBAdmissions`

`> class(UCBAdmissions)`

`> dim(UCBAdmissions)`

Let's select the second 2 by 2 table to perform a chi-square test of
independence.

`> dat = UCBAdmissions[,,2]`

`> dat`

When we pass a vector of values to `chisq.test`, a test of homogeneity
is performed by default. When we pass a table or matrix, a test of
independence is performed.

`> chisq.test(dat)`

The default in **[R]{.sans-serif}** is to use Yates' continuity
correction for 2x2 tables. You can opt not to use it.

`> chisq.test(dat, correct=FALSE)`

## Fisher's Exact Test

Pearson Chi-Square tests rely on an approximation that becomes poor as
cell sizes get small. With smaller samples, Fisher's Exact Test might be
a good alternative. However, there are many flavors of Fisher's test.
**[R]{.sans-serif}** has implemented many of them, including one in the
base package.

`> fisher.test(dat)`

# Linear Models

In a Linear Model, the expected value (mean) of a response variable,
$Y$, is modeled as a linear combination of one or more predictors. The
usual formulation of a linear model is as follows.
$$E[Y] = \beta_0 + \beta_1X_1 + ... + \beta_pX_p$$ We can also write
down a version of the model that includes a random component.
$$Y = \beta_0 + \beta_1X_1 + ... + \beta_pX_p + \epsilon$$

**Examples of Linear Models**

-   Simple Linear Regression -- only one predictor

-   ANOVA -- the predictors are dummy variables representing group
    membership

-   Multiple Linear Regression -- the predictors can be any combination
    of binary, nominal, ordinal, and continuous

Even an independent samples t-test is an example of a linear model. In
this case, there is only one predictor, $X$, which is a dummy variable
representing the group.

### Another example of data entry

The *linmod.csv* data set contains the following measurements on 255
individuals.

-   Systolic Blood Pressure

-   Diastolic Blood Pressure

-   Combined Blood Pressure

-   Age

-   Gender

-   Smoking Status

We begin by reading in the data.

`> dat = read.csv("linmod.csv", header=TRUE)`

Before beginning any modeling, it's important to investigate the data to
make sure it is there as you expect. If we just type `dat` at the
command line, **[R]{.sans-serif}** prints the entire data set. This is
not the most efficient way to explore the data. Here we explore several
different ways of exploring the data set in a more concise manner.

The `dim` function returns the dimensions of the data set; the `head`
and `tail` functions enables us to see the first and last rows of the
data set.

`> class(dat)`

`> names(dat)`

`> dim(dat)`

`> head(dat)`

`> head(dat, 15)`

`> tail(dat)`

The `summary` function is a powerful method for summarizing variables in
the data set.

`> summary(dat)`

The output includes a numeric summary for the variables *sbp* and *dbp*.
The *bp* column is read as *character* (and converted to a factor)
because it contains the character "/". Instead of a numeric summary for
*bp*, `summary` returns a table of values for the factor levels.

We would expect *age* to be a continuous variable, but
**[R]{.sans-serif}** returns a table summary for *age* rather than a
numeric summary. This indicates that *age* is being read as a factor,
and we should check for strings in the age column. In the *smoke*
column, we see that one person has the value $888$ and two the value
$999$.

Another powerful function for investigating the structure of a data set
is the `str` command.

`> str(dat)`

The output lists *age* as a *factor* which confirms our suspicion that
*age* is being read as a character variable. For factors, we can
investigate the factor levels with the `levels` command.

`> levels(dat$age)`

Someone has recorded "Not Reported\" in the age column for one person.
With a data set as small as ours, we could type `dat` and scroll down to
find out which person had a "Not Reported\" for age. With large data
sets this is difficult. The `which` statement is another option.

`> which(dat$age == "Not Reported")`

`> dat[which(dat$age == "Not Reported"), ]`

Now let's investigate the *smoke* variable.

`> levels(dat$smoke)`

`> which(dat$smoke == "888")`

`> which(dat$smoke == "999")`

**Fixing the Data** Suppose that 888 and 999 and "Not Reported" all
indicate missing values. Let's update the *age* and *smoke* variables by
putting NA to represent missingness.

`> dat$age[189] = NA`

`> dat$smoke[c(83,80,91)] = NA`

`> summary(dat$smoke)`

`> dat$smoke = factor(dat$smoke)`

`> summary(dat$smoke)`

**Common Data Management Problem!**

We still need to change *age* to a numeric variable. Just using
`as.numeric` won't work on *factors*.

`> as.numeric(dat$age)`

Instead, we must first change it to character and then numeric.

`> as.numeric(as.character(dat$age))`

`> dat$age = as.numeric(as.character(dat$age))`

### Solution

Another alternative is to read the data set using the `na.strings`
argument.

`> dat = read.csv("linmod.csv", na.strings=c("NA","Not Reported","888","999"))`

**Graphical Descriptions of Blood Pressure** Let's start by examining
the marginal distribution of Systolic Blood Pressure.

`> hist(dat$sbp, main="Histogram of Systolic Blood Pressure", xlab="Systolic BP")`

`> boxplot(dat$sbp, main="Boxplot of SBP", ylab="SBP")`

Now use the `plot` function to create a scatterplot of Systolic Blood
Pressure versus Diastolic Blood Pressure. Suppose we want Diastolic
Blood Pressure on the horizontal axis and Systolic Blood Pressure on the
vertical axis. The horizontal axis is the first argument and the
vertical axis is the second argument.

`> plot(sbp `$\sim$` dbp, data=dat)`

`plot` has many arguments which will allow us to modify the graph. Let's
take a look at a few of them.

`> plot(sbp `$\sim$` dbp, data=dat, col="green")`

`> plot(sbp `$\sim$` dbp, data=dat, pch=2, col="green")`

`> plot(sbp `$\sim$` dbp, data=dat, pch=2, xlab="Diastolic",`

`+ ylab="Systolic", main="Blood Pressure", col="green")`

**Numerical Descriptions of Blood Pressure** Using the `sd`, `cov`, and
`cor` functions, we can investigate the marginal and joint variation of
Diastolic and Systolic Blood Pressure.

`> summary(dat$dbp)`

`> summary(dat$sbp)`

`> sd(dat$dbp)`

`> sd(dat$sbp)`

`> cov(dat$dbp, dat$sbp)`

`> cor(dat$dbp, dat$sbp)`

## Simple Linear Regression using the `lm` function

In a simple linear regression, we propose the model:
$$Y = \beta_0 + \beta_1 X + \epsilon,$$ where $Y$ is the dependent
variable, $X$ is the sole independent variable, and $\epsilon$
represents a random component. One of the goals in a simple linear
regression is to find the estimates, $\hat{\beta_0}$ and
$\hat{\beta_1}$, that fit the data best.

The **[R]{.sans-serif}** function used to fit regression models is the
`lm` function. Let's begin by doing a simple linear regression of
systolic blood pressure on diastolic blood pressure.

`> lm(sbp `$\sim$` dbp, data=dat)`

At first glance, **[R]{.sans-serif}** returns the estimated regression
parameters $\hat{\beta_0}$ and $\hat{\beta_1}$ but very little else.
What about the model $r^2$? How do we find the residuals? What about
confidence intervals, influential points, or the other diagnostics one
should consider when performing a regression analysis?

By storing the fitted model as an object, we are able to unleash all the
power in the `lm` function. Let's try again, but this time, store the
linear model as an object.

`> mymod = lm(sbp `$\sim$` dbp, data=dat)`

The variable `mymod` now stores the information from the regression of
`sbp` on `dbp`. `mymod` is a linear model object. Just as we earlier saw
examples of numeric objects (`x = 5`) and character objects
(`y = "Hi"`), we now have the object `mymod` which is a linear model
object. Let's verify that `mymod` is a linear model object.

`> class(mymod)`

Now that we have the "lm\" object stored in `mymod`, let's do some more
investigation.

`> summary(mymod)`

The `summary` function returns the following

-   A 5-number summary of the residuals

-   A table of regression coefficients, standard errors, t-statistics,
    and p-values for testing the hypotheses that $\beta_i = 0$

-   An estimate of the error standard deviation

-   Unadjusted and adjusted model $r^2$

-   An overall F-test of no model effect

We can use the names function to see everything that is stored in
`mymod`.

`> names(mymod)`

We can extract any single attribute using \$.

`> mymod$coefficients`

`> mymod$fitted.values`

**[R]{.sans-serif}** has many "extractor" functions:

`> coef(mymod)`

`> fitted(mymod)`

**[R]{.sans-serif}** also has powerful graphing tools for checking model
assumptions. For a simple linear regression, we need to check for

-   The nature of the relationship between $Y$ and $X$ (linear?)

-   The error distribution

-   Influential points

Using the `plot` function, we can cycle through diagnostic graphs to
test each of the above assumptions.

`> plot(residuals(mymod), predict(mymod), main="Residual Plot")`

Confidence intervals for the regression coefficients provide much more
information than p-values. Confidence intervals for $\beta_0$ and
$\beta_1$ can be generated using the `confint` function.

`> confint(mymod)`

`> confint(mymod, level=.90)`

We can also examine the ANOVA table associated with the regression
model.

`> anova(mymod)`

## Analysis of Variance

Suppose one wishes to do a 2-way ANOVA model, where diastolic blood
pressure is the response with gender and smoking status the two factors.
As always, it is important to begin by investigating the relationships
graphically.

`> boxplot(dbp `$\sim$` smoke, data=dat)`

`> boxplot(dbp `$\sim$` gen, data=dat)`

`> with(dat, interaction.plot(smoke, gen, dbp))`

Since an ANOVA model is simply a linear model where the only predictors
are dummy variables representing group membership, ANOVA models can be
fit using the `lm` function.

`> lm.mod = lm(dbp `$\sim$` gen + smoke, data=dat)`

`> summary(lm.mod)`

Many researchers prefer output organized in a different ANOVA table. We
can also use the `aov` function to fit an ANOVA model.

`> aov.mod = aov(dbp `$\sim$` gen + smoke, data=dat)`

`> summary(aov.mod)`

`lm.mod` and `aov.mod` represent the same fit but the `summary` function
reports them differently. `summary` is an example of a generic function.
Different versions are used for different classes. Remember that we used
`summary` earlier to describe numeric vectors, factors, and data.frames.
Let's investigate the class of the two models.

`> class(lm.mod)`

`> class(aov.mod)`

The following commands give the mean of the dependent variable and each
factor level:

`> model.tables(aov.mod)`

`> ?model.tables`

We can use Tukey's HSD procedure to test the pairwise differences,
adjusting for multiple testing:

`> TukeyHSD(aov.mod)`

`> ?TukeyHSD`

## Multiple Linear Regression

A multiple linear regression assumes the following relationship:
$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \epsilon$$
In this notation, $Y$ represents the response variable of interest, and
the $X_j$ correspond to predictor variables. When fitting a linear
regression model, one aim to estimate the $\beta$ parameters. The fitted
model is sometimes used to predict future responses.

We will use the built-in LifeCycleSavings data set (which we saw in
passing earlier) to illustrate fitting a multiple linear regression. We
will use the popular `car` (Companion to Applied Regression) package for
some regression diagnostics.

`> data()`

Let's first begin by learning about the data set.

`> help(LifeCycleSavings)`

Shorten the name.

`> Life=LifeCycleSavings`

Now let's make a boxplot of each of the five variables. For comparison,
it would be helpful to view all of the plots on the same output. The
`par` and `mfrow` commands are useful for this. The `par` function
allows you to set graphical parameters, and `mfrow` allows you to
specify an array of plots.

The following commands set up a two by two grid of plots.

`> par(mfrow=c(2,2))`

We can add boxplots one at a time.

`> boxplot(Life$sr, main="sr")`

`> boxplot(Life$pop15, main="pop15")`

`> boxplot(Life$pop75, main="pop75")`

`> boxplot(Life$dpi, main="dpi")`

After exploring the marginal relationships of each of the variables, it
is a good idea to investigate the bivariate relationships. We do this
both numerically and graphically.

`> cor(Life)`

`> pairs(Life, panel=panel.smooth)`

Now fit a multiple regression model using the `lm` function.

`> mr.mod = lm(sr `$\sim$` pop15 + pop75 + dpi + ddpi, data=Life)`

`> summary(mr.mod)`

`> confint(mr.mod)`

We saw that there was a large negative correlation between pop75 and
pop15. One diagnostic for multicolinearity is the variance inflation
factor (VIF). Let's investigate the variance inflation factors. It has
been implemented in the `car` package. To access the function we must
load the package:

`> library(car)`

`> ?vif`

`> vif(mr.mod)`

How does the model change if we leave out one of the variables? We fit a
different model removing pop75.

`> mr.mod2 = lm(sr `$\sim$` pop15 + dpi + ddpi, data=Life)`

We now perform an F test for nested models.

`> anova(mr.mod, mr.mod2, test="F")`

# Lists

## String Manipulation

In the third column of *dat*, systolic and diastolic pressure were
placed together separated by a "/". Ideally, data would never be stored
in such a manner. For easy data processing, systolic and diastolic blood
pressure should be stored in separate columns. Although in our data sets
we did have separate columns, suppose for the sake of example that we
only had the one column in which blood pressure was entered as $120/82$.
It could be time consuming to convert these to separate variables by
hand in Excel.

Fortunately, **[R]{.sans-serif}** has excellent string manipulation
facilities. In this example, we will use the `strsplit` function to
extract diastolic and systolic blood pressures. `strsplit` has two
arguments that we will use. The first argument is the character string
we wish to split. The second argument is the character that we will
split on. Let's start with the *bp* value in the first row.

`> b = dat$bp[1]`

`> b`

Now let's try to split `b` into two separate values.

`> strsplit(b, split="/")`

This didn't work. When a problem like this arises, be sure to look at
the error messages! In this example, **[R]{.sans-serif}** complains that
we have a "non-character\" argument. Let's investigate.

`> class(b)`

Sure enough, b is a factor since it was obtained by indexing a factor in
the data set. We must first change b to a character.

`> b = as.character(b)`

`> class(b)`

Now we are ready!

`> strsplit(b, split="/")`

This seems to work, but in order to use the separated values, we must
first store the split string as an object.

`> sep = strsplit(b, split="/")`

`> sep`

`> class(sep)`

## Lists

The object `sep` is a list, a class of objects that we have not yet
encountered explicitly (however, data.frames are lists). Lists can
simultaneously store many objects of various classes. Recall from
earlier that elements of a vector were forced to be of the same class
(e.g., character). Lists are much more flexible and can contain
characters, vectors, matrices, data.frames, and even other lists. Let's
take a detour from our original problem of separating blood pressures in
order to investigate lists.

Create a list containing a single number, a character, and a vector of
number.

`> L = list(5, "Hi", c(3,8,7))`

`> L`

The syntax for indexing lists is different than that for vectors or
matrices. If we type `L[1]`, we obtain the sub-list containing 5 instead
of just the number 5.

`> L[1]`

`> class(L[1])`

Instead, we must use double-brackets to extract the number 5 rather than
the sublist containing the number 5.

`> L[[1]]`

`> class(L[[1]])`

The following extracts the 8 from the third element of the list.

`> L[[3]][2]`

Now that we have a basic understanding of lists. Let's return to our
problem of separating diastolic and systolic blood pressure.

`> sep`

`> s = sep[[1]][1]`

`> d = sep[[1]][2]`

`> s`

`> d`

`> s = as.numeric(s)`

`> d = as.numeric(d)`

`> s`

`> d`

It worked! Now we need to do this for every person. One way this can be
accomplished is with a `for` loop or `*apply`. We will revisit this
after covering programming. You can try the following but more is
needed.

`> strsplit(as.character(dat$bp), split="/")`

# Generalized Linear Models (GLM)

In practice, GLMs are often used when the response variable is not
continuous. Several examples of GLMs include

-   Logistic Regression (Y is binary)

-   Multinomial Logistic Regression (Y is nominal)

-   Poisson Regression (Y is a count)

-   Negative Binomial Regression (Y is a count with over-dispersion)

**[R]{.sans-serif}** uses the function `glm` to fit GLMs. We will use
logistic regression to illustrate `glm`.

## Logistic Regression

Logistic regression is a specific type of GLM used to model a binary
outcome. If we label a success "1" and a failure "0", the *odds* of
success are defined as $P(Y=1)/P(Y=0)$. Logistic regression models the
log odds of success as a linear combination of the predictors.
$${\rm log}\left(\frac{P(Y=1|X)}{P(Y=0|X)}\right) =  \beta_0 + \beta_1X_1 + ... + \beta_pX_p$$

In logistic regression, $\beta_i$ is the effect of $X_i$ on the log odds
of success ($Y=1$).

For an example, we use the "Mroz\" data in the *car* library. Let's
first review the "Mroz" data set.

`> library(car)`

`> help(Mroz)`

The syntax for `glm` is nearly the same as the syntax for `lm`. One
important additional argument is *family*, which specifies what type of
GLM will be fit. Logistic regression models a binary response, so we use
the binomial family.

`> mroz.mod = glm(lfp `$\sim$` I(k5==0) + age + wc + hc + lwg + inc, data=Mroz,`

`+   family=binomial)`

`> summary(mroz.mod)`

The fitted object `mroz.mod` is of a new type of class.

`> class(mroz.mod)`

We can extract the estimated coefficients using `coef`.

`> coef(mroz.mod)`

When reporting the effects of a logistic regression analysis, it is
common to include the effect on the *odds* of success. Since $\beta_i$
is the effect of $X_i$ on the log odds of success, $e^{\beta_i}$ is the
effect of $X_i$ on the odds of success[^1]. We can estimate the effects
of the predictors on the odds by exponentiating the coefficients.

`> exp(coef(mroz.mod))`

We can also obtain confidence intervals for both the log odds and odds
effects.

`> confint(mroz.mod)`

`> exp(confint(mroz.mod))`

# Creating Functions

Another very nice feature of **[R]{.sans-serif}** is the ability to
easily write your own programs and functions. We will begin by creating
a new function called `add.machine` that will simply sum two numbers:

`add.machine `$=$` function(num1, num2){`\
`result `$=$` num1 `$+$` num2`\
`return(result)`\
`}`

The following are important components of the code above:

-   `add.machine` is the name of the newly created object

-   `function` declares that `add.machine` will be a function

-   `num1` and `num2` are the arguments that `add.machine` will take as
    input

-   The body of the function is enclosed in curly braces

-   `return` (is optional) but specifies the output that is returned
    from the function

Let's test out the newly created function

`> add.machine`

`> add.machine(3,5)`

What happens if we don't specify valid arguments?

`> add.machine(3)`

`> add.machine(3, "Hi")`

# Programming

Programming in **[R]{.sans-serif}** is basically the same as programming
in any other language; the core program is controlled by a series of
if-then statements, loops, print statements, calls to other programs,
and return statements. The only differences are minor syntax conventions
that just take practice.

## Branching

To begin with, let's look at an example of how if-then statements work
in **[R]{.sans-serif}**. Try submitting this command at the prompt to
see how it works:

`> if (1>0) print("I Like Binary")`

Note that **[R]{.sans-serif}** prints "I Like Binary\" because the
condition in the *if* statement is true. The `print` function is very
useful for programming purposes, in that it prints simple strings in the
**[R]{.sans-serif}** Console. No explicitly labeled *then* statement is
needed after an *if* statement; you simply type what you would like
**[R]{.sans-serif}** to do if the *if* condition is true. In general, if
you want to do more than one thing if the *if* condition is true, you
use this bracketed structure:

`if (logical condition) {`\
`do this`\
`and this`\
`and this`\
`}`

The statements in the brackets usually refer to function calls and
object assignments, and simply need to be on separate lines (no
punctuation necessary!). If necessary, you can use an "else" option:

`> if (x>5) print("x is big") else print("x is small")`

## Looping

Now let's take a look at how a "for" loop works in **[R]{.sans-serif}**.
Try submitting the following syntax at the command prompt:

`> for (i in 1:5) print(i)`

**[R]{.sans-serif}** prints 1, 2, 3, 4, and 5. *For* loops work like
*if* conditions, and if you want **[R]{.sans-serif}** to do more than
one thing in a *for* loop, use brackets around the commands:

`for(i in a:b) {`\
`do this`\
`and this`\
`and this`\
`}`

`while` and `repeat` loops in **[R]{.sans-serif}** work in a manner very
similar to other programming languages. One or more commands are
executed repeatedly while a condition remains true. Typically a counter
object is initialized for controlling the loop, and then incremented
within the while loop while certain commands are executed for each
repetition. The loop ends when the while condition is false.

`t = 0`\
`while(t < 7) {`\
`print(t)`\
`t = t+1`\
`}`

## Blood Pressure Example Revisited

Earlier we dealt with a data set where diastolic and systolic blood
pressure had been read into a single column separated. We learned how to
extract the two blood pressures using the `strsplit` function. Now that
we have discussed creating functions and programming, we will separate
the two measurements for the entire data set. We begin by clearing up
the workspace.

`> ls()`

`> rm(list=ls())`

`> dat = read.csv("linmod.csv", header=TRUE, na.strings=c("NA", 888, 999, "Not Reported"))`

Extract a blood pressure for practice.

`> b = dat$bp[1]`

Recall that the following commands successfully extracted the separated
measurements.

`> ## Change to character.`

`> b = as.character(b)`

`> sep = strsplit(b, split="/")`

`> ## Extract systolic blood pressure.`

`> s = sep[[1]][1]`

`> ## Extract diastolic blood pressure.`

`> d = sep[[1]][2]`

`> ## Convert to numeric.`

`> s = as.numeric(s)`

`> d = as.numeric(d)`

Now we enclose the following commands in a function. We will name this
function `extract.bp`.

`> extract.bp = function(x) {`

`> x = as.character(x)`

`> sep = strsplit(x, split="/")`

`> s = as.numeric(sep[[1]][1])`

`> d = as.numeric(sep[[1]][2])`

`> return(c(s,d))`

`> } `

Type `extract.bp` at the command line to verify the creation of the
function was successful.

`> extract.bp`

Now let's experiment to see if our function works.

`> b`

`> extract.bp(b)`

The following code uses a loop to extract the blood pressures for each
variable in the data set.

`> ## Number of rows in the data set.`

`> n = dim(dat)[1]`

`> ## Set up empty numeric vectors to store two blood pressures.`

`> systolic = numeric(n)`

`> diastolic = numeric(n)`

`> ## Loop over the rows and extract.`

`> for (j in 1:n){`

`> out = extract.bp(dat$bp[j])`

`> systolic[j] = out[1]`

`> diastolic[j] = out[2]`

`> } `

`> systolic`

`> diastolic`

## The `apply` Function

The `apply` function performs a function on each row or column of a
matrix. (There are other \*apply functions for other situations.) First
create a couple matrices to play with. In addition to the `matrix`
function, `rbind` (or `cbind`) can be used to create matrices. For
example,

`> c1 = c(2, 9, 3)`

`> c2 = c(12, 1, 5)`

`> M2 = cbind(c1, c2)`

`> M2`

`> apply(M2, 2, mean)`

In the example above, `apply` took three arguments:

1.  The first argument, "M2" is the matrix

2.  The second argument, "2", is an index indicating the function is
    applied separately for each column, a value of "1" would apply the
    function on each row

3.  The last argument is the function that is applied

If you were to just type `mean(M2)`, the mean would be computed over the
entire matrix.

`> mean(M2)`

[^1]: $\beta_i$ is an additive effect, and $e^{\beta_i}$ is a
    multiplicative effect. For example, if $\beta_i = 0.38$, we would
    estimate that the log odds of success increases by 0.38 for every
    unit increase in $X_i$. If $e^{\beta_i} = 1.46$, we would estimate
    that the odds of success increases by 46 *percent* for every unit
    increase in $X_i$.
